{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Ollama and deploy your own large language model (LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open terminal in VScode (Terminal -> New Terminal) \n",
    "2. Execute `uv sync` to install and update the Python dependencies defined in the pyproject.toml\n",
    "3. Execute `curl -fsSL https://ollama.com/install.sh | sh`\n",
    "4. Execute `CUDA_VISIBLE_DEVICES=1 ollama serve &`\n",
    "5. Execute `ollama run gemma3:4b-it-qat`\n",
    "6. **Solve** the exercise and questions in \"evaluate_python_skills.ipynb\" with the help of the deployed model\n",
    "7. Is there any other model better suited at https://ollama.com/library\n",
    "8. Delete models `ollama list` to show models `ollama rm gemma3:4b-it-qat` to delete models. FREE UP some space on Galadriel\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
